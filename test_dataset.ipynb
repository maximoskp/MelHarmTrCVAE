{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_utils import SeparatedMelHarmMarkovDataset\n",
    "import os\n",
    "import numpy as np\n",
    "from harmony_tokenizers_m21 import ChordSymbolTokenizer, RootTypeTokenizer, \\\n",
    "    PitchClassTokenizer, RootPCTokenizer, GCTRootPCTokenizer, \\\n",
    "    GCTSymbolTokenizer, GCTRootTypeTokenizer, MelodyPitchTokenizer, \\\n",
    "    MergedMelHarmTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BartForConditionalGeneration, BartConfig, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/ssd2/maximos/data/hooktheory_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chordSymbolTokenizer = ChordSymbolTokenizer.from_pretrained('saved_tokenizers/ChordSymbolTokenizer')\n",
    "rootTypeTokenizer = RootTypeTokenizer.from_pretrained('saved_tokenizers/RootTypeTokenizer')\n",
    "pitchClassTokenizer = PitchClassTokenizer.from_pretrained('saved_tokenizers/PitchClassTokenizer')\n",
    "rootPCTokenizer = RootPCTokenizer.from_pretrained('saved_tokenizers/RootPCTokenizer')\n",
    "melodyPitchTokenizer = MelodyPitchTokenizer.from_pretrained('saved_tokenizers/MelodyPitchTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_chordSymbolTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, chordSymbolTokenizer)\n",
    "m_rootTypeTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootTypeTokenizer)\n",
    "m_pitchClassTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, pitchClassTokenizer)\n",
    "m_rootPCTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootPCTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChordSymbolTokenizer\n"
     ]
    }
   ],
   "source": [
    "print(m_chordSymbolTokenizer.harmony_tokenizer.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = m_chordSymbolTokenizer\n",
    "\n",
    "dataset = SeparatedMelHarmMarkovDataset(root_dir, tokenizer, max_length=512, num_bars=64)\n",
    "# Data collator for BART\n",
    "def create_data_collator(tokenizer, model):\n",
    "    return DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_config = BartConfig(\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=tokenizer.bos_token_id,\n",
    "    forced_eos_token_id=tokenizer.eos_token_id,\n",
    "    max_position_embeddings=512,\n",
    "    encoder_layers=8,\n",
    "    encoder_attention_heads=8,\n",
    "    encoder_ffn_dim=512,\n",
    "    decoder_layers=8,\n",
    "    decoder_attention_heads=8,\n",
    "    decoder_ffn_dim=512,\n",
    "    d_model=512,\n",
    "    encoder_layerdrop=0.3,\n",
    "    decoder_layerdrop=0.3,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "model = BartForConditionalGeneration(bart_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = create_data_collator(tokenizer, model=model)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/.local/lib/python3.11/site-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n",
      "/home/maximos/.local/lib/python3.11/site-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n",
      "In /home/maximos/.local/lib/python3.11/site-packages/matplotlib/mpl-data/stylelib/seaborn-v0_8-deep.mplstyle: .flat is deprecated.  Call .flatten() instead\n",
      "In /home/maximos/.local/lib/python3.11/site-packages/matplotlib/mpl-data/stylelib/seaborn-v0_8-notebook.mplstyle: .flat is deprecated.  Call .flatten() instead\n",
      "/home/maximos/.local/lib/python3.11/site-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n",
      "/home/maximos/.local/lib/python3.11/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8333, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(b['transitions'][5].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 348, 348])\n"
     ]
    }
   ],
   "source": [
    "print(b['transitions'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "class GraphConditioningModule(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        \"\"\"\n",
    "        Graph Neural Network that processes a batch of Markov transition matrices \n",
    "        and extracts one conditioning vector per graph.\n",
    "        \n",
    "        Args:\n",
    "            in_dim (int): Input node feature dimension (dummy features if not available)\n",
    "            hidden_dim (int): Hidden layer dimension\n",
    "            out_dim (int): Output conditioning vector dimension\n",
    "        \"\"\"\n",
    "        super(GraphConditioningModule, self).__init__()\n",
    "        \n",
    "        # Graph Attention Network (GAT) for learning node embeddings\n",
    "        self.gnn1 = GATConv(in_dim, hidden_dim)\n",
    "        self.gnn2 = GATConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Fully connected layer to transform pooled graph embedding\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, batch_graph, node_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_graph (Batch): PyG Batch containing all graphs in the batch\n",
    "            node_indices (torch.Tensor): Shape (batch_size,), selected node per sample\n",
    "        \n",
    "        Returns:\n",
    "            condition_vectors (torch.Tensor): Shape (batch_size, out_dim)\n",
    "        \"\"\"\n",
    "        x = torch.ones((batch_graph.num_nodes, 1), device=batch_graph.edge_index.device)  # Dummy node features\n",
    "        \n",
    "        # Forward pass through GNN\n",
    "        x = F.relu(self.gnn1(x, batch_graph.edge_index))\n",
    "        x = F.relu(self.gnn2(x, batch_graph.edge_index))\n",
    "        \n",
    "        # Extract the node embeddings of the selected nodes\n",
    "        node_embeddings = x[node_indices]  # Shape: (batch_size, hidden_dim)\n",
    "\n",
    "        # Pass through a linear layer to generate conditioning vectors\n",
    "        condition_vectors = self.fc(node_embeddings)  # Shape: (batch_size, out_dim)\n",
    "\n",
    "        return condition_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# latent_dim = 128\n",
    "# condition_dim = 64\n",
    "# num_nodes = 100  # Number of nodes per transition matrix\n",
    "# hidden_dim = 128\n",
    "# batch_size = 32\n",
    "# seq_length = 50  # Example sequence length\n",
    "\n",
    "# cvae = CVAE(encoder, decoder, latent_dim, condition_dim, hidden_dim, num_nodes)\n",
    "# optimizer = optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "\n",
    "def build_batch_graphs(markov_matrices):\n",
    "    \"\"\"\n",
    "    Converts a batch of Markov transition matrices into a single batched PyTorch Geometric graph.\n",
    "\n",
    "    Args:\n",
    "        markov_matrices (torch.Tensor): (batch_size, num_nodes, num_nodes) tensor\n",
    "\n",
    "    Returns:\n",
    "        batch_graph (Batch): Batched PyG graph containing all transition matrices\n",
    "        node_indices (torch.Tensor): (batch_size,) tensor containing a node index per sample\n",
    "    \"\"\"\n",
    "    batch_size, num_nodes, _ = markov_matrices.shape\n",
    "    graphs = []\n",
    "    node_indices = []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # Extract nonzero entries (source, target) where transition probability > 0\n",
    "        source_nodes, target_nodes = torch.nonzero(markov_matrices[b], as_tuple=True)\n",
    "        edge_probs = markov_matrices[b][source_nodes, target_nodes]  # Extract transition probabilities\n",
    "\n",
    "        # Create edge_index\n",
    "        edge_index = torch.stack([source_nodes, target_nodes], dim=0)  # Shape (2, num_edges)\n",
    "        \n",
    "        # Create graph data object\n",
    "        graph = Data(edge_index=edge_index, edge_attr=edge_probs, num_nodes=num_nodes)\n",
    "        graphs.append(graph)\n",
    "\n",
    "        # Select a random node to condition on (or use a rule)\n",
    "        node_indices.append(torch.randint(0, num_nodes, (1,)))\n",
    "\n",
    "    # Batch all graphs into a single PyG Batch object\n",
    "    batch_graph = Batch.from_data_list(graphs)\n",
    "    node_indices = torch.cat(node_indices)  # Shape (batch_size,)\n",
    "\n",
    "    return batch_graph, node_indices\n",
    "# end build_batch_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_graph, node_indices = build_batch_graphs( b['transitions'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 208], edge_attr=[208], num_nodes=11136, batch=[11136], ptr=[33])\n",
      "tensor([314, 239, 265, 130, 283, 178,  29, 225, 118, 137, 190, 215, 209,  75,\n",
      "        322, 169, 229,  96, 334, 327,  96, 152, 294, 300,  96, 103, 315, 140,\n",
      "          4, 330, 316, 303])\n"
     ]
    }
   ],
   "source": [
    "print(batch_graph)\n",
    "print(node_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vae_loss(recon_x, x, mu, logvar):\n",
    "#     \"\"\"Computes VAE loss (Reconstruction + KL Divergence).\"\"\"\n",
    "#     recon_loss = F.mse_loss(recon_x, x, reduction=\"sum\")  # Change to CE for text\n",
    "#     kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())  # KL Divergence\n",
    "#     return recon_loss + kl_div\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # === Generate a new batch of Markov transition matrices === #\n",
    "#     markov_matrices = torch.rand(batch_size, num_nodes, num_nodes)  # Example: Random transition matrices\n",
    "#     markov_matrices = markov_matrices / markov_matrices.sum(dim=-1, keepdim=True)  # Normalize rows\n",
    "\n",
    "#     # === Convert batch of matrices into a batched PyG graph === #\n",
    "#     batch_graph, node_indices = build_batch_graphs(markov_matrices)\n",
    "\n",
    "#     # === Generate Random Input Data (Replace with real input) === #\n",
    "#     input_ids = torch.randint(0, 1000, (batch_size, seq_length))  # Example tokenized input\n",
    "#     attention_mask = torch.ones_like(input_ids)  # Dummy attention mask\n",
    "\n",
    "#     # === Forward Pass (Now batch-processed) === #\n",
    "#     recon_x, mu, logvar = cvae(input_ids, attention_mask, batch_graph, node_indices)\n",
    "    \n",
    "#     total_loss = vae_loss(recon_x, input_ids, mu, logvar)\n",
    "#     total_loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
