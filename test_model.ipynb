{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BartModel\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv  # Or GATConv for Graph Attention Networks\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Constructing a graph (Markov transition table)\n",
    "def create_graph_from_markov_table(transition_matrix):\n",
    "    # transition_matrix is of shape (num_nodes, num_nodes) and should be sparse\n",
    "    # Convert to edge index format for PyG (2 x num_edges)\n",
    "    num_nodes = transition_matrix.shape[0]\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if transition_matrix[i, j] > 0:  # Only consider non-zero transitions\n",
    "                edge_index.append([i, j])  # Directed edge from i to j\n",
    "                edge_attr.append(transition_matrix[i, j])  # Transition probability\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # Node features can be initialized randomly or based on node properties\n",
    "    x = torch.randn(num_nodes, 10)  # Random initial features for each node (example)\n",
    "\n",
    "    # Create PyG data object\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvae_loss(reconstructed, original, mu, logvar):\n",
    "    reconstruction_loss = nn.MSELoss()(reconstructed, original)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return reconstruction_loss + kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BartModel\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "\n",
    "# === Load Pretrained BART Model === #\n",
    "bart = BartModel.from_pretrained(\"facebook/bart-base\")\n",
    "encoder, decoder = bart.encoder, bart.decoder\n",
    "\n",
    "# Freeze BART parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# === CVAE with Integrated GNN Conditioning Module === #\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, latent_dim, condition_dim, hidden_dim, num_nodes, use_gat=False, lstm_layers=2):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.latent_dim = latent_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        encoder_hidden_dim = encoder.config.hidden_size\n",
    "\n",
    "        # === GNN Conditioning Module === #\n",
    "        self.node_embeddings = nn.Parameter(torch.randn(num_nodes, hidden_dim))\n",
    "\n",
    "        if use_gat:\n",
    "            self.gnn1 = GATConv(hidden_dim, hidden_dim, heads=4, concat=True)\n",
    "            self.gnn2 = GATConv(hidden_dim * 4, condition_dim, heads=1, concat=False)\n",
    "        else:\n",
    "            self.gnn1 = GCNConv(hidden_dim, hidden_dim)\n",
    "            self.gnn2 = GCNConv(hidden_dim, condition_dim)\n",
    "\n",
    "        # === BiLSTM Encoder === #\n",
    "        self.lstm_encoder = nn.LSTM(encoder_hidden_dim, hidden_dim, lstm_layers, \n",
    "                                    batch_first=True, bidirectional=True)\n",
    "\n",
    "        # === VAE Bottleneck === #\n",
    "        self.fc_mu = nn.Linear(hidden_dim * 2 + condition_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim * 2 + condition_dim, latent_dim)\n",
    "\n",
    "        # === BiLSTM Decoder === #\n",
    "        self.lstm_decoder = nn.LSTM(latent_dim + condition_dim, hidden_dim, lstm_layers, \n",
    "                                    batch_first=True, bidirectional=True)\n",
    "        self.fc_decode = nn.Linear(hidden_dim * 2, encoder_hidden_dim)\n",
    "\n",
    "    def gnn_forward(self, edge_index, edge_attr, node_indices):\n",
    "        \"\"\"GNN forward pass to compute node conditioning vectors\"\"\"\n",
    "        x = self.node_embeddings\n",
    "        x = F.relu(self.gnn1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.gnn2(x, edge_index, edge_attr))\n",
    "        return x[node_indices]  # Shape: (batch_size, condition_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, edge_index, edge_attr, node_indices):\n",
    "        # === Compute GNN-Based Conditioning === #\n",
    "        condition_vector = self.gnn_forward(edge_index, edge_attr, node_indices)\n",
    "\n",
    "        # === Encode Input with Frozen BART Encoder === #\n",
    "        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "\n",
    "        # === BiLSTM Encoder === #\n",
    "        lstm_out, _ = self.lstm_encoder(encoder_outputs)  # (batch, seq_len, hidden_dim * 2)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take last time step (batch, hidden_dim * 2)\n",
    "\n",
    "        # === VAE Reparameterization === #\n",
    "        lstm_out = torch.cat([lstm_out, condition_vector], dim=-1)  # (batch, hidden_dim * 2 + condition_dim)\n",
    "        mu = self.fc_mu(lstm_out)\n",
    "        logvar = self.fc_logvar(lstm_out)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # === Concatenate Latent Vector with Condition === #\n",
    "        z = torch.cat([z, condition_vector], dim=-1)\n",
    "        z = z.unsqueeze(1).repeat(1, input_ids.shape[1], 1)  # Repeat for each time step\n",
    "\n",
    "        # === BiLSTM Decoder === #\n",
    "        lstm_out, _ = self.lstm_decoder(z)\n",
    "        decoder_inputs = self.fc_decode(lstm_out)\n",
    "\n",
    "        # === Decode with Frozen BART Decoder === #\n",
    "        decoder_outputs = self.decoder(inputs_embeds=decoder_inputs).last_hidden_state\n",
    "        return decoder_outputs, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "latent_dim = 128\n",
    "condition_dim = 64\n",
    "num_nodes = 100  # Number of nodes in the transition matrix\n",
    "hidden_dim = 128\n",
    "batch_size = 32\n",
    "seq_length = 50  # Example sequence length\n",
    "\n",
    "cvae = CVAE(encoder, decoder, latent_dim, condition_dim, hidden_dim, num_nodes)\n",
    "optimizer = optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "\n",
    "edge_index = torch.randint(0, num_nodes, (2, 500))  # Random Graph Edges\n",
    "edge_attr = None  # No edge weights\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction=\"sum\")  # Change to CE for text\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())  # KL Divergence\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Select conditioning nodes for batch\n",
    "    node_indices = torch.randint(0, num_nodes, (batch_size,))\n",
    "\n",
    "    # Random Input Data (Replace with real input)\n",
    "    input_ids = torch.randint(0, 1000, (batch_size, seq_length))  # Example tokenized input\n",
    "    attention_mask = torch.ones_like(input_ids)  # Dummy attention mask\n",
    "\n",
    "    # Forward Pass\n",
    "    recon_x, mu, logvar = cvae(input_ids, attention_mask, edge_index, edge_attr, node_indices)\n",
    "\n",
    "    # Compute Loss\n",
    "    loss = vae_loss(recon_x, input_ids, mu, logvar)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "latent_dim = 128\n",
    "condition_dim = 64\n",
    "num_nodes = 100  # Number of nodes in the transition matrix\n",
    "hidden_dim = 128\n",
    "batch_size = 32\n",
    "seq_length = 50  # Example sequence length\n",
    "\n",
    "cvae = CVAE(encoder, decoder, latent_dim, condition_dim, hidden_dim, num_nodes)\n",
    "optimizer = optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "\n",
    "def build_graph_from_markov(markov_matrices):\n",
    "    \"\"\"\n",
    "    Converts a batch of Markov transition matrices into edge_index and edge_attr.\n",
    "\n",
    "    Args:\n",
    "        markov_matrices (torch.Tensor): (batch_size, num_nodes, num_nodes) tensor\n",
    "\n",
    "    Returns:\n",
    "        edge_indices (list of torch.Tensor): List of edge_index tensors per batch item\n",
    "        edge_attrs (list of torch.Tensor): List of edge_attr tensors per batch item\n",
    "    \"\"\"\n",
    "    batch_size, num_nodes, _ = markov_matrices.shape\n",
    "    edge_indices = []\n",
    "    edge_attrs = []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # Extract nonzero entries (source, target) where transition probability > 0\n",
    "        source_nodes, target_nodes = torch.nonzero(markov_matrices[b], as_tuple=True)\n",
    "        edge_probs = markov_matrices[b][source_nodes, target_nodes]  # Extract transition probabilities\n",
    "\n",
    "        # Create edge_index\n",
    "        edge_index = torch.stack([source_nodes, target_nodes], dim=0)  # Shape (2, num_edges)\n",
    "        edge_indices.append(edge_index)\n",
    "        edge_attrs.append(edge_probs)\n",
    "\n",
    "    return edge_indices, edge_attrs\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    \"\"\"Computes VAE loss (Reconstruction + KL Divergence).\"\"\"\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction=\"sum\")  # Change to CE for text\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())  # KL Divergence\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # === Generate a new batch of Markov transition matrices === #\n",
    "    markov_matrices = torch.rand(batch_size, num_nodes, num_nodes)  # Example: Random transition matrices\n",
    "    markov_matrices = markov_matrices / markov_matrices.sum(dim=-1, keepdim=True)  # Normalize rows\n",
    "\n",
    "    # === Convert to graph format === #\n",
    "    edge_indices, edge_attrs = build_graph_from_markov(markov_matrices)\n",
    "\n",
    "    # Select conditioning nodes for batch\n",
    "    node_indices = torch.randint(0, num_nodes, (batch_size,))\n",
    "\n",
    "    # === Generate Random Input Data (Replace with real input) === #\n",
    "    input_ids = torch.randint(0, 1000, (batch_size, seq_length))  # Example tokenized input\n",
    "    attention_mask = torch.ones_like(input_ids)  # Dummy attention mask\n",
    "\n",
    "    # === Forward Pass (Process each graph separately) === #\n",
    "    total_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        recon_x, mu, logvar = cvae(\n",
    "            input_ids[i].unsqueeze(0),\n",
    "            attention_mask[i].unsqueeze(0),\n",
    "            edge_indices[i],\n",
    "            edge_attrs[i],\n",
    "            node_indices[i].unsqueeze(0),\n",
    "        )\n",
    "        total_loss += vae_loss(recon_x, input_ids[i].unsqueeze(0), mu, logvar)\n",
    "\n",
    "    total_loss /= batch_size  # Normalize loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
